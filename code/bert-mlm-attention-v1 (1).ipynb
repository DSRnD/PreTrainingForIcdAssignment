{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-08T08:24:04.675243Z","iopub.execute_input":"2022-04-08T08:24:04.675908Z","iopub.status.idle":"2022-04-08T08:24:04.733476Z","shell.execute_reply.started":"2022-04-08T08:24:04.675808Z","shell.execute_reply":"2022-04-08T08:24:04.73279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data =  pd.read_csv('/kaggle/input/mimic-clean-text/MIMIC-III-Final_cleaned.csv')[:1500]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:04.761815Z","iopub.execute_input":"2022-04-08T08:24:04.762119Z","iopub.status.idle":"2022-04-08T08:24:21.253065Z","shell.execute_reply.started":"2022-04-08T08:24:04.762088Z","shell.execute_reply":"2022-04-08T08:24:21.25235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape, data.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:21.254621Z","iopub.execute_input":"2022-04-08T08:24:21.254886Z","iopub.status.idle":"2022-04-08T08:24:21.262546Z","shell.execute_reply.started":"2022-04-08T08:24:21.254848Z","shell.execute_reply":"2022-04-08T08:24:21.261862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:21.263739Z","iopub.execute_input":"2022-04-08T08:24:21.264312Z","iopub.status.idle":"2022-04-08T08:24:21.290621Z","shell.execute_reply.started":"2022-04-08T08:24:21.264275Z","shell.execute_reply":"2022-04-08T08:24:21.289995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport collections\nimport re\nimport unicodedata\nimport six\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:21.292617Z","iopub.execute_input":"2022-04-08T08:24:21.292858Z","iopub.status.idle":"2022-04-08T08:24:25.825968Z","shell.execute_reply.started":"2022-04-08T08:24:21.292825Z","shell.execute_reply":"2022-04-08T08:24:25.82524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_unicode(text):\n  \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n  if six.PY3:\n    if isinstance(text, str):\n      return text\n    elif isinstance(text, bytes):\n      return text.decode(\"utf-8\", \"ignore\")\n    else:\n      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n  elif six.PY2:\n    if isinstance(text, str):\n      return text.decode(\"utf-8\", \"ignore\")\n    elif isinstance(text, unicode):\n      return text\n    else:\n      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n  else:\n    raise ValueError(\"Not running on Python2 or Python 3?\")","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.827111Z","iopub.execute_input":"2022-04-08T08:24:25.827364Z","iopub.status.idle":"2022-04-08T08:24:25.836939Z","shell.execute_reply.started":"2022-04-08T08:24:25.827309Z","shell.execute_reply":"2022-04-08T08:24:25.836204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport numpy as np\nimport six\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.839568Z","iopub.execute_input":"2022-04-08T08:24:25.839748Z","iopub.status.idle":"2022-04-08T08:24:25.843968Z","shell.execute_reply.started":"2022-04-08T08:24:25.839726Z","shell.execute_reply":"2022-04-08T08:24:25.843081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicTokenizer(object):\n  \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n\n  def __init__(self, do_lower_case=True):\n    \"\"\"Constructs a BasicTokenizer.\n\n    Args:\n      do_lower_case: Whether to lower case the input.\n    \"\"\"\n    self.do_lower_case = do_lower_case\n\n  def tokenize(self, text):\n    \"\"\"Tokenizes a piece of text.\"\"\"\n    text = convert_to_unicode(text)\n    text = self._clean_text(text)#perform invalid char removal and whitespace removal\n\n    # This was added on November 1st, 2018 for the multilingual and Chinese\n    # models. This is also applied to the English models now, but it doesn't\n    # matter since the English models were not trained on any Chinese data\n    # and generally don't have any Chinese data in them (there are Chinese\n    # characters in the vocabulary because Wikipedia does have some Chinese\n    # words in the English Wikipedia.).\n    text = self._tokenize_chinese_chars(text)\n\n    orig_tokens = whitespace_tokenize(text)\n    split_tokens = []\n    for token in orig_tokens:\n      if self.do_lower_case:\n        token = token.lower()\n        token = self._run_strip_accents(token)\n      split_tokens.extend(self._run_split_on_punc(token))\n\n    output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n    return output_tokens\n\n  def _run_strip_accents(self, text):\n    \"\"\"Strips accents from a piece of text.\"\"\"\n    text = unicodedata.normalize(\"NFD\", text)\n    output = []\n    for char in text:\n      cat = unicodedata.category(char)\n      if cat == \"Mn\":\n        continue\n      output.append(char)\n    return \"\".join(output)\n\n  def _run_split_on_punc(self, text):\n    \"\"\"Splits punctuation on a piece of text.\"\"\"\n    chars = list(text)\n    i = 0\n    start_new_word = True\n    output = []\n    while i < len(chars):\n      char = chars[i]\n      if _is_punctuation(char):\n        output.append([char])\n        start_new_word = True\n      else:\n        if start_new_word:\n          output.append([])\n        start_new_word = False\n        output[-1].append(char)\n      i += 1\n\n    return [\"\".join(x) for x in output]\n\n  def _tokenize_chinese_chars(self, text):\n    \"\"\"Adds whitespace around any CJK character.\"\"\"\n    output = []\n    for char in text:\n      cp = ord(char)\n      if self._is_chinese_char(cp):\n        output.append(\" \")\n        output.append(char)\n        output.append(\" \")\n      else:\n        output.append(char)\n    return \"\".join(output)\n\n  def _is_chinese_char(self, cp):\n    \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n    # This defines a \"chinese character\" as anything in the CJK Unicode block:\n    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n    #\n    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n    # despite its name. The modern Korean Hangul alphabet is a different block,\n    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n    # space-separated words, so they are not treated specially and handled\n    # like the all of the other languages.\n    if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n        (cp >= 0x3400 and cp <= 0x4DBF) or  #\n        (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n        (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n        (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n        (cp >= 0x2B820 and cp <= 0x2CEAF) or\n        (cp >= 0xF900 and cp <= 0xFAFF) or  #\n        (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n      return True\n\n    return False\n\n  def _clean_text(self, text):\n    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n    output = []\n    for char in text:\n      cp = ord(char)\n      if cp == 0 or cp == 0xfffd or _is_control(char):\n        continue\n      if _is_whitespace(char):\n        output.append(\" \")\n      else:\n        output.append(char)\n    return \"\".join(output)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.845749Z","iopub.execute_input":"2022-04-08T08:24:25.845944Z","iopub.status.idle":"2022-04-08T08:24:25.865701Z","shell.execute_reply.started":"2022-04-08T08:24:25.845921Z","shell.execute_reply":"2022-04-08T08:24:25.864789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_vocab(vocab_file):\n  \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n  vocab = collections.OrderedDict()\n  index = 0\n  #with tf.gfile.GFile(vocab_file, \"r\") as reader:\n  with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n    while True:\n      token = convert_to_unicode(reader.readline())\n      if not token:\n        break\n      token = (token.strip()).split(\"\\t\")\n      vocab[token[0]] = index\n      index += 1\n  print(\"\\nVocab loading done!\")\n  return vocab","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.867162Z","iopub.execute_input":"2022-04-08T08:24:25.867671Z","iopub.status.idle":"2022-04-08T08:24:25.877268Z","shell.execute_reply.started":"2022-04-08T08:24:25.867635Z","shell.execute_reply":"2022-04-08T08:24:25.876594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordpieceTokenizer(object):\n  \"\"\"Runs WordPiece tokenziation.\"\"\"\n\n  def __init__(self, vocab, unk_token=\"[UNK]\", max_input_chars_per_word=200):\n    self.vocab = vocab\n    self.unk_token = unk_token\n    self.max_input_chars_per_word = max_input_chars_per_word\n\n  def tokenize(self, text):\n    \"\"\"Tokenizes a piece of text into its word pieces.\n\n    This uses a greedy longest-match-first algorithm to perform tokenization\n    using the given vocabulary.\n\n    For example:\n      input = \"unaffable\"\n      output = [\"un\", \"##aff\", \"##able\"]\n\n    Args:\n      text: A single token or whitespace separated tokens. This should have\n        already been passed through `BasicTokenizer.\n\n    Returns:\n      A list of wordpiece tokens.\n    \"\"\"\n\n    text = convert_to_unicode(text)\n\n    output_tokens = []\n    for token in whitespace_tokenize(text):\n      chars = list(token)\n      if len(chars) > self.max_input_chars_per_word:\n        output_tokens.append(self.unk_token)\n        #print(\"\\nunknown token inserted\")\n        continue\n\n      is_bad = False\n      start = 0\n      sub_tokens = []\n      while start < len(chars):\n        end = len(chars)\n        cur_substr = None\n        while start < end:\n          substr = \"\".join(chars[start:end])\n          if start > 0:\n            substr = \"##\" + substr\n          if substr in self.vocab:\n            cur_substr = substr\n            #print(\"\\nknown token inserted\", cur_substr)\n            break\n          end -= 1\n        if cur_substr is None:\n          is_bad = True\n          break\n        sub_tokens.append(cur_substr)\n        start = end\n\n      if is_bad:\n        output_tokens.append(self.unk_token)\n        #print(\"\\nunknown token inserted\") #This is where unknown tokens are being inserted\n      else:\n        output_tokens.extend(sub_tokens)\n    return output_tokens\n\n\ndef _is_whitespace(char):\n  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n  # \\t, \\n, and \\r are technically contorl characters but we treat them\n  # as whitespace since they are generally considered as such.\n  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n    return True\n  cat = unicodedata.category(char)\n  if cat == \"Zs\":\n    return True\n  return False\n\n\ndef _is_control(char):\n  \"\"\"Checks whether `chars` is a control character.\"\"\"\n  # These are technically control characters but we count them as whitespace\n  # characters.\n  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n    return False\n  cat = unicodedata.category(char)\n  if cat in (\"Cc\", \"Cf\"):\n    return True\n  return False\n\n\ndef _is_punctuation(char):\n  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n  cp = ord(char)\n  # We treat all non-letter/number ASCII as punctuation.\n  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n  # Punctuation class but we treat them as punctuation anyways, for\n  # consistency.\n  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n    return True\n  cat = unicodedata.category(char)\n  if cat.startswith(\"P\"):\n    return True\n  return False","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.879092Z","iopub.execute_input":"2022-04-08T08:24:25.87951Z","iopub.status.idle":"2022-04-08T08:24:25.895613Z","shell.execute_reply.started":"2022-04-08T08:24:25.879416Z","shell.execute_reply":"2022-04-08T08:24:25.894843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FullTokenizer(object):\n  \"\"\"Runs end-to-end tokenziation.\"\"\"\n\n  def __init__(self, vocab_file, do_lower_case=True):\n    self.vocab = load_vocab(vocab_file)#Create Vocab dist with index 0\n    self.inv_vocab = {v: k for k, v in self.vocab.items()}#Get vocab dict with index as key and token as value\n    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)#Initialize the basic tokenizer \n    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n\n  def tokenize(self, text):\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text):\n      #for sub_token in self.wordpiece_tokenizer.tokenize(token):\n        split_tokens.append(token)\n\n    return split_tokens\n\n  def convert_tokens_to_ids(self, tokens):\n    return convert_by_vocab(self.vocab, tokens)\n\n  def convert_ids_to_tokens(self, ids):\n    return convert_by_vocab(self.inv_vocab, ids)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.899117Z","iopub.execute_input":"2022-04-08T08:24:25.899297Z","iopub.status.idle":"2022-04-08T08:24:25.90791Z","shell.execute_reply.started":"2022-04-08T08:24:25.899275Z","shell.execute_reply":"2022-04-08T08:24:25.907149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = FullTokenizer(\n      vocab_file='/kaggle/input/autoencoderdecoderonpmcembeddingvocab/Vocab.txt', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:25.909326Z","iopub.execute_input":"2022-04-08T08:24:25.909647Z","iopub.status.idle":"2022-04-08T08:24:26.079908Z","shell.execute_reply.started":"2022-04-08T08:24:25.90955Z","shell.execute_reply":"2022-04-08T08:24:26.079112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_by_vocab(vocab, items):\n  \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n  output = []\n  for item in items:\n    output.append(vocab[item])\n  return output\n\n\ndef convert_tokens_to_ids(vocab, tokens):\n  return convert_by_vocab(vocab, tokens)\n\n\ndef convert_ids_to_tokens(inv_vocab, ids):\n  return convert_by_vocab(inv_vocab, ids)\n\n\ndef whitespace_tokenize(text):\n  \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n  text = text.strip()\n  if not text:\n    return []\n  tokens = text.split()\n  return tokens","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:26.081276Z","iopub.execute_input":"2022-04-08T08:24:26.081535Z","iopub.status.idle":"2022-04-08T08:24:26.087615Z","shell.execute_reply.started":"2022-04-08T08:24:26.0815Z","shell.execute_reply":"2022-04-08T08:24:26.086633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.tokenize(\"\\This is the string\")","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:26.089103Z","iopub.execute_input":"2022-04-08T08:24:26.089402Z","iopub.status.idle":"2022-04-08T08:24:26.09943Z","shell.execute_reply.started":"2022-04-08T08:24:26.089368Z","shell.execute_reply":"2022-04-08T08:24:26.098541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanText(sentence):\n        sentence = re.sub(\n        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n        sentence = re.sub(r\"\\,+\", \",\", sentence)\n        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n        sentence = re.sub(r'[0-9]', \" \", sentence)\n        sentence = re.sub(r'[^\\w\\s]','',sentence)\n        sentence = re.sub(r'(?:^| )\\w(?:$| )', ' ', (sentence)).strip()#AKS\n        sentence = sentence.lower()\n        #return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]\n        return sentence","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:26.101067Z","iopub.execute_input":"2022-04-08T08:24:26.10131Z","iopub.status.idle":"2022-04-08T08:24:26.108574Z","shell.execute_reply.started":"2022-04-08T08:24:26.101278Z","shell.execute_reply":"2022-04-08T08:24:26.107844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processTextIntoSentences(text):\n    if(not len(text)):\n        print(\"\\nGiven string is empty. Please check again\")\n    sentenceSize  = 125\n    #sentenceSize = 256\n    line = convert_to_unicode(text)\n    line  = cleanText(text)\n    tokens = tokenizer.tokenize(line)\n    #print(\"\\nTokens\", tokens)\n    if(tokens):\n        all_tokens = [tokens[i: i+sentenceSize] for i in range(0, len(tokens), sentenceSize)]\n        #print(\"\\nbatched tokens\", len(all_tokens), all_tokens)\n        processedTokens = []\n        for token_ in all_tokens:\n            processedTokens.append(\" \".join(token_))\n        #print(len(processedTokens[1].split()))\n        return (\"|\".join(processedTokens))\n    \n            \n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:26.10985Z","iopub.execute_input":"2022-04-08T08:24:26.11014Z","iopub.status.idle":"2022-04-08T08:24:26.120095Z","shell.execute_reply.started":"2022-04-08T08:24:26.110105Z","shell.execute_reply":"2022-04-08T08:24:26.119371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['processedText'] = data.apply(lambda x:processTextIntoSentences(x['clean_text']) , axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:24:26.121292Z","iopub.execute_input":"2022-04-08T08:24:26.121622Z","iopub.status.idle":"2022-04-08T08:25:04.232447Z","shell.execute_reply.started":"2022-04-08T08:24:26.121588Z","shell.execute_reply":"2022-04-08T08:25:04.231704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape, data.columns, len((data['processedText'][0]).split('|')[0].split())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.233693Z","iopub.execute_input":"2022-04-08T08:25:04.234024Z","iopub.status.idle":"2022-04-08T08:25:04.240986Z","shell.execute_reply.started":"2022-04-08T08:25:04.233984Z","shell.execute_reply":"2022-04-08T08:25:04.240074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build the vocabulary on training dataset","metadata":{}},{"cell_type":"code","source":"import pickle\nimport tqdm\nfrom collections import Counter","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.242818Z","iopub.execute_input":"2022-04-08T08:25:04.243213Z","iopub.status.idle":"2022-04-08T08:25:04.24976Z","shell.execute_reply.started":"2022-04-08T08:25:04.243173Z","shell.execute_reply":"2022-04-08T08:25:04.248916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"((list(data['processedText']))[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.251494Z","iopub.execute_input":"2022-04-08T08:25:04.251838Z","iopub.status.idle":"2022-04-08T08:25:04.260289Z","shell.execute_reply.started":"2022-04-08T08:25:04.251802Z","shell.execute_reply":"2022-04-08T08:25:04.259388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = ''\ntrainingDocs = list(data['processedText'])\nfor doc in trainingDocs:\n    texts = texts + doc","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.261703Z","iopub.execute_input":"2022-04-08T08:25:04.261949Z","iopub.status.idle":"2022-04-08T08:25:04.278232Z","shell.execute_reply.started":"2022-04-08T08:25:04.261918Z","shell.execute_reply":"2022-04-08T08:25:04.277539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(texts.split())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.279383Z","iopub.execute_input":"2022-04-08T08:25:04.279722Z","iopub.status.idle":"2022-04-08T08:25:04.451159Z","shell.execute_reply.started":"2022-04-08T08:25:04.279686Z","shell.execute_reply":"2022-04-08T08:25:04.45029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TorchVocab(object):\n    \"\"\"Defines a vocabulary object that will be used to numericalize a field.\n    Attributes:\n        freqs: A collections.Counter object holding the frequencies of tokens\n            in the data used to build the Vocab.\n        stoi: A collections.defaultdict instance mapping token strings to\n            numerical identifiers.\n        itos: A list of token strings indexed by their numerical identifiers.\n    \"\"\"\n\n    def __init__(self, counter, max_size=None, min_freq=1, specials=['<pad>', '<oov>'],\n                 vectors=None, unk_init=None, vectors_cache=None):\n        \"\"\"Create a Vocab object from a collections.Counter.\n        Arguments:\n            counter: collections.Counter object holding the frequencies of\n                each value found in the data.\n            max_size: The maximum size of the vocabulary, or None for no\n                maximum. Default: None.\n            min_freq: The minimum frequency needed to include a token in the\n                vocabulary. Values less than 1 will be set to 1. Default: 1.\n            specials: The list of special tokens (e.g., padding or eos) that\n                will be prepended to the vocabulary in addition to an <unk>\n                token. Default: ['<pad>']\n            vectors: One of either the available pretrained vectors\n                or custom pretrained vectors (see Vocab.load_vectors);\n                or a list of aforementioned vectors\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: torch.Tensor.zero_\n            vectors_cache: directory for cached vectors. Default: '.vector_cache'\n        \"\"\"\n        self.freqs = counter\n        counter = counter.copy()\n        min_freq = max(min_freq, 1)\n\n        self.itos = list(specials)\n        # frequencies of special tokens are not counted when building vocabulary\n        # in frequency order\n        for tok in specials:\n            del counter[tok]\n\n        max_size = None if max_size is None else max_size + len(self.itos)\n\n        # sort by frequency, then alphabetically\n        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n\n        for word, freq in words_and_frequencies:\n            if freq < min_freq or len(self.itos) == max_size:\n                break\n            self.itos.append(word)\n\n        # stoi is simply a reverse dict for itos\n        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n\n        self.vectors = None\n        if vectors is not None:\n            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n        else:\n            assert unk_init is None and vectors_cache is None\n\n    def __eq__(self, other):\n        if self.freqs != other.freqs:\n            return False\n        if self.stoi != other.stoi:\n            return False\n        if self.itos != other.itos:\n            return False\n        if self.vectors != other.vectors:\n            return False\n        return True\n\n    def __len__(self):\n        return len(self.itos)\n\n    def vocab_rerank(self):\n        self.stoi = {word: i for i, word in enumerate(self.itos)}\n\n    def extend(self, v, sort=False):\n        words = sorted(v.itos) if sort else v.itos\n        for w in words:\n            if w not in self.stoi:\n                self.itos.append(w)\n                self.stoi[w] = len(self.itos) - 1\n\n\nclass Vocab(TorchVocab):\n    def __init__(self, counter, max_size=None, min_freq=1):\n        self.pad_index = 0\n        self.unk_index = 1\n        self.eos_index = 2\n        self.sos_index = 3\n        self.mask_index = 4\n        super().__init__(counter, specials=[\"<pad>\", \"<unk>\", \"<eos>\", \"<sos>\", \"<mask>\"],\n                         max_size=max_size, min_freq=min_freq)\n\n    def to_seq(self, sentece, seq_len, with_eos=False, with_sos=False) -> list:\n        pass\n\n    def from_seq(self, seq, join=False, with_pad=False):\n        pass\n\n    @staticmethod\n    def load_vocab(vocab_path: str) -> 'Vocab':\n        with open(vocab_path, \"rb\") as f:\n            return pickle.load(f)\n\n    def save_vocab(self, vocab_path):\n        with open(vocab_path, \"wb\") as f:\n            pickle.dump(self, f)\n\n\n# Building Vocab with text files\nclass WordVocab(Vocab):\n    def __init__(self, texts, max_size=None, min_freq=1):\n        print(\"Building Vocab\")\n        counter = Counter()\n        count = 0\n        words = ((texts.replace(\"\\n\", \"\").replace(\"\\t\", \"\")).replace(\"|\",\" \")).split()\n        for word in words:\n            counter[word] += 1\n            count += 1\n        print(\"\\nTotal line\", count)\n        super().__init__(counter, max_size=max_size, min_freq=min_freq)\n\n    def to_seq(self, sentence, seq_len=None, with_eos=False, with_sos=False, with_len=False):\n        if isinstance(sentence, str):\n            sentence = sentence.split()\n\n        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n\n        if with_eos:\n            seq += [self.eos_index]  # this would be index 1\n        if with_sos:\n            seq = [self.sos_index] + seq\n\n        origin_seq_len = len(seq)\n\n        if seq_len is None:\n            pass\n        elif len(seq) <= seq_len:\n            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n        else:\n            seq = seq[:seq_len]\n\n        return (seq, origin_seq_len) if with_len else seq\n\n    def from_seq(self, seq, join=False, with_pad=False):\n        words = [self.itos[idx]\n                 if idx < len(self.itos)\n                 else \"<%d>\" % idx\n                 for idx in seq\n                 if not with_pad or idx != self.pad_index]\n\n        return \" \".join(words) if join else words\n\n    @staticmethod\n    def load_vocab(vocab_path: str) -> 'WordVocab':\n        with open(vocab_path, \"rb\") as f:\n            return pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.452796Z","iopub.execute_input":"2022-04-08T08:25:04.453195Z","iopub.status.idle":"2022-04-08T08:25:04.484737Z","shell.execute_reply.started":"2022-04-08T08:25:04.453155Z","shell.execute_reply":"2022-04-08T08:25:04.484005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newvocab = WordVocab(texts,100000,1)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:04.485881Z","iopub.execute_input":"2022-04-08T08:25:04.486278Z","iopub.status.idle":"2022-04-08T08:25:05.3307Z","shell.execute_reply.started":"2022-04-08T08:25:04.486235Z","shell.execute_reply":"2022-04-08T08:25:05.32928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(newvocab.stoi)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.332122Z","iopub.execute_input":"2022-04-08T08:25:05.332401Z","iopub.status.idle":"2022-04-08T08:25:05.338428Z","shell.execute_reply.started":"2022-04-08T08:25:05.332363Z","shell.execute_reply":"2022-04-08T08:25:05.337517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('vocabOn30k2minFreqNew.txt' , 'w') as f:\n    for key, val in (newvocab.stoi).items():\n        f.write(\"%s\\t%s\\n\"%(key,val))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.340105Z","iopub.execute_input":"2022-04-08T08:25:05.340634Z","iopub.status.idle":"2022-04-08T08:25:05.359737Z","shell.execute_reply.started":"2022-04-08T08:25:05.340596Z","shell.execute_reply":"2022-04-08T08:25:05.359113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newvocab.save_vocab('vocabOn30k2minfreqNew.txt')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.360909Z","iopub.execute_input":"2022-04-08T08:25:05.36137Z","iopub.status.idle":"2022-04-08T08:25:05.375602Z","shell.execute_reply.started":"2022-04-08T08:25:05.361318Z","shell.execute_reply":"2022-04-08T08:25:05.374852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab = WordVocab.load_vocab('vocabOn30k2minfreqNew.txt')\nlen(newvocab.stoi)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.376895Z","iopub.execute_input":"2022-04-08T08:25:05.377411Z","iopub.status.idle":"2022-04-08T08:25:05.393874Z","shell.execute_reply.started":"2022-04-08T08:25:05.377373Z","shell.execute_reply":"2022-04-08T08:25:05.393138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['processedText'][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.398858Z","iopub.execute_input":"2022-04-08T08:25:05.399373Z","iopub.status.idle":"2022-04-08T08:25:05.405847Z","shell.execute_reply.started":"2022-04-08T08:25:05.399324Z","shell.execute_reply":"2022-04-08T08:25:05.405008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:05.407048Z","iopub.execute_input":"2022-04-08T08:25:05.407909Z","iopub.status.idle":"2022-04-08T08:25:13.955173Z","shell.execute_reply.started":"2022-04-08T08:25:05.407873Z","shell.execute_reply":"2022-04-08T08:25:13.954365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:13.958441Z","iopub.execute_input":"2022-04-08T08:25:13.958678Z","iopub.status.idle":"2022-04-08T08:25:15.310304Z","shell.execute_reply.started":"2022-04-08T08:25:13.958651Z","shell.execute_reply":"2022-04-08T08:25:15.309547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gensim\nfrom gensim.models.keyedvectors import KeyedVectors","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:15.311797Z","iopub.execute_input":"2022-04-08T08:25:15.312056Z","iopub.status.idle":"2022-04-08T08:25:15.798798Z","shell.execute_reply.started":"2022-04-08T08:25:15.312019Z","shell.execute_reply":"2022-04-08T08:25:15.798106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegmentEmbedding(nn.Embedding):\n    def __init__(self, embed_size=512):\n        super().__init__(3, embed_size, padding_idx=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:15.800136Z","iopub.execute_input":"2022-04-08T08:25:15.800478Z","iopub.status.idle":"2022-04-08T08:25:15.807202Z","shell.execute_reply.started":"2022-04-08T08:25:15.80044Z","shell.execute_reply":"2022-04-08T08:25:15.806556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionalEmbedding(nn.Module):\n\n    def __init__(self, d_model, max_len=256):\n        super().__init__()\n\n        # Compute the positional encodings once in log space.\n        pe = torch.zeros(max_len, d_model).float()\n        pe.require_grad = False\n\n        position = torch.arange(0, max_len).float().unsqueeze(1)\n        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        return self.pe[:, :x.size(1)]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:15.808474Z","iopub.execute_input":"2022-04-08T08:25:15.808817Z","iopub.status.idle":"2022-04-08T08:25:15.818268Z","shell.execute_reply.started":"2022-04-08T08:25:15.808745Z","shell.execute_reply":"2022-04-08T08:25:15.817496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word_model = KeyedVectors.load_word2vec_format(\"/kaggle/input/pmcmodel/PMC-w2v.bin\", binary=True)\nprint('Found %s word vectors.' % len(word_model.index_to_key))\nprint(word_model['Cholera'].shape)\nmatrix_len = len(newvocab.stoi)\nweights_matrix = np.zeros((matrix_len, 200))\nwords_found = 0\n\nfor word, i in (newvocab.stoi.items()):\n    try: \n        weights_matrix[i] = word_model[word]\n        words_found += 1\n    except KeyError:\n        weights_matrix[i] = np.random.normal(scale=0.6, size=(200, ))\nprint('words not found',len(newvocab.stoi)- words_found, weights_matrix.shape )\nweights_matrix","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:25:15.819417Z","iopub.execute_input":"2022-04-08T08:25:15.819777Z","iopub.status.idle":"2022-04-08T08:26:01.052907Z","shell.execute_reply.started":"2022-04-08T08:25:15.819742Z","shell.execute_reply":"2022-04-08T08:26:01.052183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_emb_layer(src_vocab_size,embed_size,non_trainable=False):\n    #num_embeddings, embedding_dim = weights_matrix.shape()\n    emb_layer = nn.Embedding(src_vocab_size, embed_size)\n    #emb_layer.load_state_dict({'weight': weights_matrix})\n    emb_layer.weight=nn.Parameter(torch.tensor(weights_matrix,dtype=torch.float32))\n    if non_trainable:\n        emb_layer.weight.requires_grad = False\n\n    return emb_layer","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.054436Z","iopub.execute_input":"2022-04-08T08:26:01.05473Z","iopub.status.idle":"2022-04-08T08:26:01.061067Z","shell.execute_reply.started":"2022-04-08T08:26:01.054693Z","shell.execute_reply":"2022-04-08T08:26:01.060196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TokenEmbedding(nn.Embedding):\n    def __init__(self, vocab_size, embed_size=512):\n        super().__init__(vocab_size, embed_size, padding_idx=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.062556Z","iopub.execute_input":"2022-04-08T08:26:01.062832Z","iopub.status.idle":"2022-04-08T08:26:01.07326Z","shell.execute_reply.started":"2022-04-08T08:26:01.062793Z","shell.execute_reply":"2022-04-08T08:26:01.072497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTEmbedding(nn.Module):\n    \"\"\"\n    BERT Embedding which is consisted with under features\n        1. TokenEmbedding : normal embedding matrix\n        2. PositionalEmbedding : adding positional information using sin, cos\n        2. SegmentEmbedding : adding sentence segment info, (sent_A:1, sent_B:2)\n\n        sum of all these features are output of BERTEmbedding\n    \"\"\"\n\n    def __init__(self, vocab_size, embed_size, dropout=0.1):\n        \"\"\"\n        :param vocab_size: total vocab size\n        :param embed_size: embedding size of token embedding\n        :param dropout: dropout rate\n        \"\"\"\n        super().__init__()\n        #self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n        self.token = create_emb_layer(vocab_size,embed_size )\n        self.position = PositionalEmbedding(d_model=self.token.embedding_dim)\n        self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n        self.dropout = nn.Dropout(p=dropout)\n        self.embed_size = embed_size\n\n    def forward(self, sequence, segment_label):\n        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.074503Z","iopub.execute_input":"2022-04-08T08:26:01.074832Z","iopub.status.idle":"2022-04-08T08:26:01.08408Z","shell.execute_reply.started":"2022-04-08T08:26:01.074791Z","shell.execute_reply":"2022-04-08T08:26:01.083225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"Construct a layernorm module (See citation for details).\"\n\n    def __init__(self, features, eps=1e-6):\n        super(LayerNorm, self).__init__()\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.085683Z","iopub.execute_input":"2022-04-08T08:26:01.085947Z","iopub.status.idle":"2022-04-08T08:26:01.093791Z","shell.execute_reply.started":"2022-04-08T08:26:01.085915Z","shell.execute_reply":"2022-04-08T08:26:01.092983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    \"Implements FFN equation.\"\n\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super(PositionwiseFeedForward, self).__init__()\n        self.w_1 = nn.Linear(d_model, d_ff)\n        self.w_2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n        self.activation = GELU()\n\n    def forward(self, x):\n        return self.w_2(self.dropout(self.activation(self.w_1(x))))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.095245Z","iopub.execute_input":"2022-04-08T08:26:01.095588Z","iopub.status.idle":"2022-04-08T08:26:01.104968Z","shell.execute_reply.started":"2022-04-08T08:26:01.095552Z","shell.execute_reply":"2022-04-08T08:26:01.104134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GELU(nn.Module):\n    \"\"\"\n    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n    \"\"\"\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.106315Z","iopub.execute_input":"2022-04-08T08:26:01.106711Z","iopub.status.idle":"2022-04-08T08:26:01.11373Z","shell.execute_reply.started":"2022-04-08T08:26:01.106676Z","shell.execute_reply":"2022-04-08T08:26:01.112935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SublayerConnection(nn.Module):\n    \"\"\"\n    A residual connection followed by a layer norm.\n    Note for code simplicity the norm is first as opposed to last.\n    \"\"\"\n\n    def __init__(self, size, dropout):\n        super(SublayerConnection, self).__init__()\n        self.norm = LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        \"Apply residual connection to any sublayer with the same size.\"\n        return x + self.dropout(sublayer(self.norm(x)))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.114738Z","iopub.execute_input":"2022-04-08T08:26:01.114927Z","iopub.status.idle":"2022-04-08T08:26:01.173974Z","shell.execute_reply.started":"2022-04-08T08:26:01.114896Z","shell.execute_reply":"2022-04-08T08:26:01.171258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    \"\"\"\n    Compute 'Scaled Dot Product Attention\n    \"\"\"\n\n    def forward(self, query, key, value, mask=None, dropout=None):\n        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n                 / math.sqrt(query.size(-1))\n\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        p_attn = F.softmax(scores, dim=-1)\n\n        if dropout is not None:\n            p_attn = dropout(p_attn)\n\n        return torch.matmul(p_attn, value), p_attn","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.1755Z","iopub.execute_input":"2022-04-08T08:26:01.175966Z","iopub.status.idle":"2022-04-08T08:26:01.18384Z","shell.execute_reply.started":"2022-04-08T08:26:01.175906Z","shell.execute_reply":"2022-04-08T08:26:01.183111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    \"\"\"\n    Take in model size and number of heads.\n    \"\"\"\n\n    def __init__(self, h, d_model, dropout=0.1):\n        super().__init__()\n        assert d_model % h == 0\n\n        # We assume d_v always equals d_k\n        self.d_k = d_model // h\n        self.h = h\n\n        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n        self.output_linear = nn.Linear(d_model, d_model)\n        self.attention = Attention()\n\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n\n        # 1) Do all the linear projections in batch from d_model => h x d_k\n        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n                             for l, x in zip(self.linear_layers, (query, key, value))]\n\n        # 2) Apply attention on all the projected vectors in batch.\n        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n\n        # 3) \"Concat\" using a view and apply a final linear.\n        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n\n        return self.output_linear(x)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.184796Z","iopub.execute_input":"2022-04-08T08:26:01.185943Z","iopub.status.idle":"2022-04-08T08:26:01.199629Z","shell.execute_reply.started":"2022-04-08T08:26:01.185891Z","shell.execute_reply":"2022-04-08T08:26:01.198754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    \"\"\"\n    Bidirectional Encoder = Transformer (self-attention)\n    Transformer = MultiHead_Attention + Feed_Forward with sublayer connection\n    \"\"\"\n\n    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n        \"\"\"\n        :param hidden: hidden size of transformer\n        :param attn_heads: head sizes of multi-head attention\n        :param feed_forward_hidden: feed_forward_hidden, usually 4*hidden_size\n        :param dropout: dropout rate\n        \"\"\"\n\n        super().__init__()\n        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden)\n        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, x, mask):\n        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n        x = self.output_sublayer(x, self.feed_forward)\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.200974Z","iopub.execute_input":"2022-04-08T08:26:01.201302Z","iopub.status.idle":"2022-04-08T08:26:01.210796Z","shell.execute_reply.started":"2022-04-08T08:26:01.201265Z","shell.execute_reply":"2022-04-08T08:26:01.209892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERT(nn.Module):\n    \"\"\"\n    BERT model : Bidirectional Encoder Representations from Transformers.\n    \"\"\"\n\n    def __init__(self, vocab_size, hidden=768, n_layers=12, attn_heads=12, dropout=0.1):\n        \"\"\"\n        :param vocab_size: vocab_size of total words\n        :param hidden: BERT model hidden size\n        :param n_layers: numbers of Transformer blocks(layers)\n        :param attn_heads: number of attention heads\n        :param dropout: dropout rate\n        \"\"\"\n\n        super().__init__()\n        self.hidden = hidden\n        self.n_layers = n_layers\n        self.attn_heads = attn_heads\n\n        # paper noted they used 4*hidden_size for ff_network_hidden_size\n        self.feed_forward_hidden = hidden * 4\n\n        # embedding for BERT, sum of positional, segment, token embeddings\n        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=hidden)\n\n        # multi-layers transformer blocks, deep network\n        self.transformer_blocks = nn.ModuleList(\n            [TransformerBlock(hidden, attn_heads, hidden * 4, dropout) for _ in range(n_layers)])\n        print(self.hidden,self.n_layers, self.attn_heads, self.feed_forward_hidden )\n    def forward(self, x, segment_info):\n        # attention masking for padded token\n        # torch.ByteTensor([batch_size, 1, seq_len, seq_len)\n        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n\n        # embedding the indexed sequence to sequence of vectors\n        x = self.embedding(x, segment_info)\n\n        # running over multiple transformer blocks\n        for transformer in self.transformer_blocks:\n            x = transformer.forward(x, mask)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.212162Z","iopub.execute_input":"2022-04-08T08:26:01.212466Z","iopub.status.idle":"2022-04-08T08:26:01.223349Z","shell.execute_reply.started":"2022-04-08T08:26:01.212432Z","shell.execute_reply":"2022-04-08T08:26:01.222644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bert = BERT(len(vocab), hidden=200, n_layers=8, attn_heads=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.224669Z","iopub.execute_input":"2022-04-08T08:26:01.224922Z","iopub.status.idle":"2022-04-08T08:26:01.406778Z","shell.execute_reply.started":"2022-04-08T08:26:01.22489Z","shell.execute_reply":"2022-04-08T08:26:01.406027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionModule(nn.Module):\n    \"\"\"\n    Building attention of clinical texts with ICD Codes#100\n    First Calculate the importance of clinical texts with code\n    Generate the common representation of all codes with using normalized weight for a particular clinical doc\n    cancatenate the clinical texts rep, attention rep and code rep\n    Pass the cancate rep through linear layer with sigmoid activation\n    \"\"\"\n    def __init__(self, hidden):\n        super().__init__()\n        self.linear = nn.Linear(3 * hidden, 1)\n        self.sigmoid  = nn.Sigmoid()\n    def forward(self,docEmbed, codeEmbed):\n        batchSize = docEmbed.shape[0]\n        embedSize = docEmbed.shape[-1]\n        codeCount = codeEmbed.shape[0]\n        score = torch.matmul(docEmbed,codeEmbed.reshape(embedSize,-1))\n        code_attn_wt = F.softmax(score, dim=-1)\n        code_attn_wt = code_attn_wt.reshape(-1, codeCount)\n        code_attn =torch.matmul(code_attn_wt, codeEmbed.reshape(-1,embedSize))\n        code_attn_doc = torch.cat((code_attn.reshape(-1,embedSize), docEmbed.reshape(-1,embedSize)), dim = -1)#cancatenating combined code and docuemnt rep\n        output_list = []\n        for index in range(codeCount):\n            code_attn_doc_code = torch.cat((code_attn_doc,  codeEmbed[index].repeat(batchSize,1)),axis = -1)\n            pred_out = self.sigmoid(self.linear(code_attn_doc_code))\n            #print(pred_out.shape)\n            output_list.append(pred_out)\n        return output_list","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.408111Z","iopub.execute_input":"2022-04-08T08:26:01.408395Z","iopub.status.idle":"2022-04-08T08:26:01.418392Z","shell.execute_reply.started":"2022-04-08T08:26:01.40836Z","shell.execute_reply":"2022-04-08T08:26:01.417608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Bert \n#bert with attention \n#bert attention and adoptive learning \n#bert attention with rwms ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.420107Z","iopub.execute_input":"2022-04-08T08:26:01.420913Z","iopub.status.idle":"2022-04-08T08:26:01.426892Z","shell.execute_reply.started":"2022-04-08T08:26:01.420875Z","shell.execute_reply":"2022-04-08T08:26:01.426012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTLM(nn.Module):\n    \"\"\"\n    BERT Language Model\n    Next Sentence Prediction Model + Masked Language Model\n    \"\"\"\n    \n    def __init__(self, bert: BERT, vocab_size):\n        \"\"\"\n        :param bert: BERT model which should be trained\n        :param vocab_size: total vocab size for masked_lm\n        \"\"\"\n\n        super().__init__()\n        self.bert = bert\n        self.next_sentence = NextSentencePrediction(self.bert.hidden)\n        self.mask_lm = MaskedLanguageModel(self.bert.hidden, vocab_size)\n        self.attentionModule = AttentionModule(self.bert.hidden)\n        \n\n    def forward(self, x, segment_label, label_input, label_segment):\n        x = self.bert(x, segment_label)\n        label_input = self.bert(label_input, label_segment)\n        code_pred = self.attentionModule(x[:,0:1,:],label_input[:,0:1,:])\n        return self.mask_lm(x), self.mask_lm(label_input), x, label_input, code_pred\n        #return self.next_sentence(x) self.mask_lm(x), self.next_sentence(label_input), self.mask_lm(label_input)\n\n\nclass NextSentencePrediction(nn.Module):\n    \"\"\"\n    2-class classification model : is_next, is_not_next\n    \"\"\"\n\n    def __init__(self, hidden):\n        \"\"\"\n        :param hidden: BERT model output size\n        \"\"\"\n        super().__init__()\n        self.linear = nn.Linear(hidden, 2)\n        self.softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, x):\n        return self.softmax(self.linear(x[:, 0]))\n\n\nclass MaskedLanguageModel(nn.Module):\n    \"\"\"\n    predicting origin token from masked input sequence\n    n-class classification problem, n-class = vocab_size\n    \"\"\"\n\n    def __init__(self, hidden, vocab_size):\n        \"\"\"\n        :param hidden: output size of BERT model\n        :param vocab_size: total vocab size\n        \"\"\"\n        super().__init__()\n        self.linear = nn.Linear(hidden, vocab_size)\n        self.softmax = nn.LogSoftmax(dim=-1)\n\n        \n    def forward(self, x):\n        return self.softmax(self.linear(x))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.428282Z","iopub.execute_input":"2022-04-08T08:26:01.428621Z","iopub.status.idle":"2022-04-08T08:26:01.441807Z","shell.execute_reply.started":"2022-04-08T08:26:01.428583Z","shell.execute_reply":"2022-04-08T08:26:01.441076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cuda_condition = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.444784Z","iopub.execute_input":"2022-04-08T08:26:01.445009Z","iopub.status.idle":"2022-04-08T08:26:01.498217Z","shell.execute_reply.started":"2022-04-08T08:26:01.444982Z","shell.execute_reply":"2022-04-08T08:26:01.497402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BERTLM(bert, len(vocab)).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:01.501642Z","iopub.execute_input":"2022-04-08T08:26:01.501881Z","iopub.status.idle":"2022-04-08T08:26:06.215209Z","shell.execute_reply.started":"2022-04-08T08:26:01.501846Z","shell.execute_reply":"2022-04-08T08:26:06.214492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.216685Z","iopub.execute_input":"2022-04-08T08:26:06.216945Z","iopub.status.idle":"2022-04-08T08:26:06.221168Z","shell.execute_reply.started":"2022-04-08T08:26:06.216908Z","shell.execute_reply":"2022-04-08T08:26:06.220252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport tqdm\nimport torch\nimport random","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.222676Z","iopub.execute_input":"2022-04-08T08:26:06.223209Z","iopub.status.idle":"2022-04-08T08:26:06.23131Z","shell.execute_reply.started":"2022-04-08T08:26:06.223172Z","shell.execute_reply":"2022-04-08T08:26:06.230563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"icdCodeDescription  = '/kaggle/input/mimicdata/ICD_desc_with_freq.csv'\ntopCodes  = 100\nicdCodes = pd.read_csv(icdCodeDescription)[:topCodes]\nicdCodeDescDict = {}\ncodes  = list(icdCodes[\"Code\"])\nDesc  = list(icdCodes[\"Long Description\"])\ncode2Index = {}\nfor i , code in enumerate(codes):\n    icdCodeDescDict[code] = Desc[i]\n    code2Index[code] = i+1\n#return icdCodeDescDict,code2Index","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.233919Z","iopub.execute_input":"2022-04-08T08:26:06.235514Z","iopub.status.idle":"2022-04-08T08:26:06.266443Z","shell.execute_reply.started":"2022-04-08T08:26:06.235475Z","shell.execute_reply":"2022-04-08T08:26:06.265532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(Desc)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.267664Z","iopub.execute_input":"2022-04-08T08:26:06.267906Z","iopub.status.idle":"2022-04-08T08:26:06.272769Z","shell.execute_reply.started":"2022-04-08T08:26:06.267874Z","shell.execute_reply":"2022-04-08T08:26:06.272137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.27402Z","iopub.execute_input":"2022-04-08T08:26:06.27488Z","iopub.status.idle":"2022-04-08T08:26:06.283168Z","shell.execute_reply.started":"2022-04-08T08:26:06.274843Z","shell.execute_reply":"2022-04-08T08:26:06.282424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def CreateTextFileLableMap():\n    trueLabels = list(data['ICD9_CODE'])\n    textFileLabel = {}\n    for i , trueLabel in enumerate(trueLabels):\n        textFileLabel[i+1]  = [y for y in trueLabel[2:-2].split(\"', '\")if y in  icdCodeDescDict]\n    return textFileLabel","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.285368Z","iopub.execute_input":"2022-04-08T08:26:06.286293Z","iopub.status.idle":"2022-04-08T08:26:06.29191Z","shell.execute_reply.started":"2022-04-08T08:26:06.286264Z","shell.execute_reply":"2022-04-08T08:26:06.291215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = CreateTextFileLableMap() # file index starts form 1","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.29317Z","iopub.execute_input":"2022-04-08T08:26:06.29355Z","iopub.status.idle":"2022-04-08T08:26:06.305349Z","shell.execute_reply.started":"2022-04-08T08:26:06.293511Z","shell.execute_reply":"2022-04-08T08:26:06.304583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.308164Z","iopub.execute_input":"2022-04-08T08:26:06.308582Z","iopub.status.idle":"2022-04-08T08:26:06.31662Z","shell.execute_reply.started":"2022-04-08T08:26:06.308547Z","shell.execute_reply":"2022-04-08T08:26:06.315865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.318626Z","iopub.execute_input":"2022-04-08T08:26:06.319606Z","iopub.status.idle":"2022-04-08T08:26:06.32618Z","shell.execute_reply.started":"2022-04-08T08:26:06.319436Z","shell.execute_reply":"2022-04-08T08:26:06.325156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['ICD9_CODE'][0],data['top_ICD'][0]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.327601Z","iopub.execute_input":"2022-04-08T08:26:06.328009Z","iopub.status.idle":"2022-04-08T08:26:06.335251Z","shell.execute_reply.started":"2022-04-08T08:26:06.327972Z","shell.execute_reply":"2022-04-08T08:26:06.334608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listIds = [i for i in range(data.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.336438Z","iopub.execute_input":"2022-04-08T08:26:06.337234Z","iopub.status.idle":"2022-04-08T08:26:06.343446Z","shell.execute_reply.started":"2022-04-08T08:26:06.337198Z","shell.execute_reply":"2022-04-08T08:26:06.342735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(listIds)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.345108Z","iopub.execute_input":"2022-04-08T08:26:06.345953Z","iopub.status.idle":"2022-04-08T08:26:06.353786Z","shell.execute_reply.started":"2022-04-08T08:26:06.34591Z","shell.execute_reply":"2022-04-08T08:26:06.353032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n  'Characterizes a dataset for PyTorch'\n  def __init__(self, list_IDs, labels):\n        'Initialization'\n        self.labels = labels\n        self.list_IDs = list_IDs\n\n  def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.list_IDs)\n\n  def __getitem__(self, index):\n        'Generates one sample of data'\n        # Select sample\n        ID = self.list_IDs[index]\n\n        # Load data and get label\n        X = data['processedText'][ID]\n        y = self.labels[ID+1]\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.355034Z","iopub.execute_input":"2022-04-08T08:26:06.355763Z","iopub.status.idle":"2022-04-08T08:26:06.41314Z","shell.execute_reply.started":"2022-04-08T08:26:06.355727Z","shell.execute_reply":"2022-04-08T08:26:06.412281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = Dataset(listIds,label )","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.414394Z","iopub.execute_input":"2022-04-08T08:26:06.415068Z","iopub.status.idle":"2022-04-08T08:26:06.422805Z","shell.execute_reply.started":"2022-04-08T08:26:06.415027Z","shell.execute_reply":"2022-04-08T08:26:06.421933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0][1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.42424Z","iopub.execute_input":"2022-04-08T08:26:06.424887Z","iopub.status.idle":"2022-04-08T08:26:06.433804Z","shell.execute_reply.started":"2022-04-08T08:26:06.424848Z","shell.execute_reply":"2022-04-08T08:26:06.433047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(dataset[0][0].split(\"|\")[4].split())","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.435365Z","iopub.execute_input":"2022-04-08T08:26:06.437795Z","iopub.status.idle":"2022-04-08T08:26:06.442863Z","shell.execute_reply.started":"2022-04-08T08:26:06.43777Z","shell.execute_reply":"2022-04-08T08:26:06.442202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = (data['processedText'][0].split('|'))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.444057Z","iopub.execute_input":"2022-04-08T08:26:06.444808Z","iopub.status.idle":"2022-04-08T08:26:06.450227Z","shell.execute_reply.started":"2022-04-08T08:26:06.444757Z","shell.execute_reply":"2022-04-08T08:26:06.4495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if(len(a) % 2): #To make even number of sentences\n            a.append(a[-1])\na","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.45155Z","iopub.execute_input":"2022-04-08T08:26:06.451996Z","iopub.status.idle":"2022-04-08T08:26:06.460115Z","shell.execute_reply.started":"2022-04-08T08:26:06.45196Z","shell.execute_reply":"2022-04-08T08:26:06.459429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = [a[i: i+2] for i in range(0, len(a), 2)] # combine two sentences ","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.461257Z","iopub.execute_input":"2022-04-08T08:26:06.461849Z","iopub.status.idle":"2022-04-08T08:26:06.46805Z","shell.execute_reply.started":"2022-04-08T08:26:06.461809Z","shell.execute_reply":"2022-04-08T08:26:06.467301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(a)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.46906Z","iopub.execute_input":"2022-04-08T08:26:06.469624Z","iopub.status.idle":"2022-04-08T08:26:06.477379Z","shell.execute_reply.started":"2022-04-08T08:26:06.469575Z","shell.execute_reply":"2022-04-08T08:26:06.476559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newvocab.stoi.get('medications', newvocab.unk_index)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.479244Z","iopub.execute_input":"2022-04-08T08:26:06.479649Z","iopub.status.idle":"2022-04-08T08:26:06.486022Z","shell.execute_reply.started":"2022-04-08T08:26:06.479614Z","shell.execute_reply":"2022-04-08T08:26:06.48519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"[newvocab.stoi.get(word, newvocab.unk_index) for word in 'were restarted on regimen at discharge the blood in your vomit was to'.split()]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.487453Z","iopub.execute_input":"2022-04-08T08:26:06.48799Z","iopub.status.idle":"2022-04-08T08:26:06.496937Z","shell.execute_reply.started":"2022-04-08T08:26:06.487953Z","shell.execute_reply":"2022-04-08T08:26:06.49618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self,vocab, seq_len, list_IDs, labels, encoding=\"utf-8\", on_memory=True):\n        self.vocab = vocab\n        self.seq_len = seq_len\n        self.codeDesc  = icdCodeDescDict\n        self.on_memory = on_memory\n        #self.corpus_lines = corpus_lines\n        self.list_IDs  = list_IDs \n        self.encoding = encoding\n        self.labels = labels\n        self.texts  = data['processedText']\n        self.desc = Desc\n        self.CodeIndex = code2Index\n\n\n    def __len__(self):\n        return len(self.list_IDs)\n    def codelabel(self, trueLabels):\n        labelIndexes = [int(self.CodeIndex[trueLabel])-1 for trueLabel in trueLabels]\n        x = torch.LongTensor(labelIndexes)\n        y_onehot = nn.functional.one_hot(x, num_classes=100)\n        y_onehot = y_onehot.sum(dim=0).float()\n        y_onehot = y_onehot.reshape(-1,1)\n        return y_onehot\n    \n    def __getitem__(self, item):# if item count start from 1 and till the size of docuemts length \n        trueLabels = self.labels[item]\n        text_ = self.texts[item-1]\n        text_ = text_.split('|')\n        if(len(text_) % 2): #To make even number of sentences\n            text_.append(text_[-1])\n        text_ = [text_[i: i+2] for i in range(0, len(text_), 2)]\n        #print(len(text_))\n        label_input = self.codelabel(trueLabels)\n        bert_input_ = self.generateTensor(text_)\n        return bert_input_, label_input\n        #return {key: torch.tensor(value) for key, value in output.items()}\n    def generateTensorOnLabels(self):\n        codeDesc  = [text for text in self.desc]\n        if(len(codeDesc) % 2): #To make even number of sentences\n            codeDesc.append(codeDesc[-1])\n        #codeDesc = [codeDesc[i: i+2] for i in range(0, len(codeDesc), 2)]\n        #print(codeDesc)\n        numberOfLines  = len(codeDesc)\n        bert_input_ = []\n        bert_label_ = []\n        segment_label_ = []\n        is_next_ = []\n        for i in range(numberOfLines):\n            is_next_label = 0\n            t1 = codeDesc[i]\n            #t1, t2, is_next_label = self.random_sent_for_Code_Desc(i, codeDesc)#generate the label for next sentence prediction in the form of 0 or 1\n            #print(\"sentence 2 is\", t2)\n            t1_random, t1_label = self.random_word(t1)#This will generate the masked token for sentence A and the label index for the masked token \n            #t2_random, t2_label = self.random_word(t2)\n\n        # [CLS] tag = SOS tag, [SEP] tag = EOS tag\n            t1 = [self.vocab.sos_index] + t1_random + [self.vocab.eos_index]\n            #t2 = t2_random + [self.vocab.eos_index]\n\n            t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index]\n            #t2_label = t2_label + [self.vocab.pad_index]\n\n            #segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n            segment_label = ([1 for _ in range(len(t1))])[:self.seq_len]\n            bert_input = (t1)[:self.seq_len]\n            #bert_input = (t1 + t2)[:self.seq_len]\n            bert_label = (t1_label)[:self.seq_len]\n            #bert_label = (t1_label + t2_label)[:self.seq_len]\n\n            padding = [self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))]#This would pad the input, output lable and sengement label up to the maximum length\n            bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n            bert_input_.append(bert_input)\n            bert_label_.append(bert_label)\n            segment_label_.append(segment_label)\n            is_next_.append(is_next_label)\n        return ([torch.tensor(bert_input_),torch.tensor(bert_label_),torch.tensor(segment_label_), torch.tensor(is_next_)])\n    def generateTensor(self, text):\n        numberOfLines  = len(text)\n        bert_input_ = []\n        bert_label_ = []\n        segment_label_ = []\n        is_next_ = []\n        for i in range(numberOfLines):\n            t1, t2, is_next_label = self.random_sent(i, text)#generate the label for next sentence prediction in the form of 0 or 1\n            t1_random, t1_label = self.random_word(t1)#This will generate the masked token for sentence A and the label index for the masked token \n            t2_random, t2_label = self.random_word(t2)\n\n        # [CLS] tag = SOS tag, [SEP] tag = EOS tag\n            t1 = [self.vocab.sos_index] + t1_random + [self.vocab.eos_index]\n            t2 = t2_random + [self.vocab.eos_index]\n\n            t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index]\n            t2_label = t2_label + [self.vocab.pad_index]\n\n            segment_label = ([1 for _ in range(len(t1))] + [2 for _ in range(len(t2))])[:self.seq_len]\n            bert_input = (t1 + t2)[:self.seq_len]\n            bert_label = (t1_label + t2_label)[:self.seq_len]\n\n            padding = [self.vocab.pad_index for _ in range(self.seq_len - len(bert_input))]#This would pad the input, output lable and sengement label up to the maximum length\n            bert_input.extend(padding), bert_label.extend(padding), segment_label.extend(padding)\n            bert_input_.append(bert_input)\n            bert_label_.append(bert_label)\n            segment_label_.append(segment_label)\n            is_next_.append(is_next_label)\n        return ([torch.tensor(bert_input_),torch.tensor(bert_label_),torch.tensor(segment_label_), torch.tensor(is_next_)])\n    def random_word(self, sentence):\n        tokens = sentence.split()\n        output_label = []\n\n        for i, token in enumerate(tokens):\n            prob = random.random()\n            if prob < 0.15:\n                prob /= 0.15\n\n                # 80% randomly change token to mask token\n                if prob < 0.8:\n                    tokens[i] = self.vocab.mask_index\n\n                # 10% randomly change token to random token\n                elif prob < 0.9:\n                    tokens[i] = random.randrange(len(self.vocab))\n\n                # 10% randomly change token to current token\n                else:\n                    tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n\n                output_label.append(self.vocab.stoi.get(token, self.vocab.unk_index))\n\n            else:\n                tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n                output_label.append(0)\n\n        return tokens, output_label\n\n    def random_sent(self, index,text):\n        t1, t2 = self.get_corpus_line(index,text)\n\n        # output_text, label(isNotNext:0, isNext:1)\n        if random.random() > 0.5:\n            return t1, t2, 1\n        else:\n            return t1, t2, 1\n        \n    def random_sent_for_Code_Desc(self, index,text):\n        t1, t2 = self.get_corpus_line(index,text)\n\n        # output_text, label(isNotNext:0, isNext:1)\n        if random.random() > 0.5:\n            return t1, t2, 0\n        else:\n            return t1, t2, 0\n    \n    def get_corpus_line(self, item,text):\n        if self.on_memory:\n            return text[item][0], text[item][1]\n        \"\"\"else:\n            line = self.file.__next__()\n            if line is None:\n                self.file.close()\n                self.file = open(self.corpus_path, \"r\", encoding=self.encoding)\n                line = self.file.__next__()\n\n            t1, t2 = line[:-1].split(\"\\t\")\n            return t1, t2\"\"\"\n\n    def get_random_line(self,text):\n        if self.on_memory:\n            return text[random.randrange(len(text))][1]\n    def topCode(self):\n        codeInput = self.generateTensorOnLabels()\n        return codeInput","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.498692Z","iopub.execute_input":"2022-04-08T08:26:06.499019Z","iopub.status.idle":"2022-04-08T08:26:06.533839Z","shell.execute_reply.started":"2022-04-08T08:26:06.498915Z","shell.execute_reply":"2022-04-08T08:26:06.532832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = BERTDataset(newvocab,256, listIds,label )","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.535193Z","iopub.execute_input":"2022-04-08T08:26:06.53566Z","iopub.status.idle":"2022-04-08T08:26:06.544486Z","shell.execute_reply.started":"2022-04-08T08:26:06.535616Z","shell.execute_reply":"2022-04-08T08:26:06.543644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#b, c= train_data[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.547555Z","iopub.execute_input":"2022-04-08T08:26:06.548449Z","iopub.status.idle":"2022-04-08T08:26:06.552889Z","shell.execute_reply.started":"2022-04-08T08:26:06.548409Z","shell.execute_reply":"2022-04-08T08:26:06.552159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#c.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.55423Z","iopub.execute_input":"2022-04-08T08:26:06.555047Z","iopub.status.idle":"2022-04-08T08:26:06.561279Z","shell.execute_reply.started":"2022-04-08T08:26:06.55501Z","shell.execute_reply":"2022-04-08T08:26:06.560549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\none_hot = MultiLabelBinarizer()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.563851Z","iopub.execute_input":"2022-04-08T08:26:06.56588Z","iopub.status.idle":"2022-04-08T08:26:06.680459Z","shell.execute_reply.started":"2022-04-08T08:26:06.565849Z","shell.execute_reply":"2022-04-08T08:26:06.679722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(train_data.topCode()[3])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.681872Z","iopub.execute_input":"2022-04-08T08:26:06.682152Z","iopub.status.idle":"2022-04-08T08:26:06.687955Z","shell.execute_reply.started":"2022-04-08T08:26:06.682113Z","shell.execute_reply":"2022-04-08T08:26:06.68719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_data.topCode()[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.689498Z","iopub.execute_input":"2022-04-08T08:26:06.690015Z","iopub.status.idle":"2022-04-08T08:26:06.696949Z","shell.execute_reply.started":"2022-04-08T08:26:06.689976Z","shell.execute_reply":"2022-04-08T08:26:06.696079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#b[1].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.698417Z","iopub.execute_input":"2022-04-08T08:26:06.698929Z","iopub.status.idle":"2022-04-08T08:26:06.705404Z","shell.execute_reply.started":"2022-04-08T08:26:06.698891Z","shell.execute_reply":"2022-04-08T08:26:06.704618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.71489Z","iopub.execute_input":"2022-04-08T08:26:06.715444Z","iopub.status.idle":"2022-04-08T08:26:06.719644Z","shell.execute_reply.started":"2022-04-08T08:26:06.715405Z","shell.execute_reply":"2022-04-08T08:26:06.718626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parser = argparse.ArgumentParser()\nparser.add_argument(\"-hs\", \"--hidden\", type=int, default=512, help=\"hidden size of transformer model\")\nparser.add_argument(\"-l\", \"--layers\", type=int, default=8, help=\"number of layers\")\nparser.add_argument(\"-a\", \"--attn_heads\", type=int, default=8, help=\"number of attention heads\")\nparser.add_argument(\"-s\", \"--seq_len\", type=int, default=20, help=\"maximum sequence len\")\n\nparser.add_argument(\"-b\", \"--batch_size\", type=int, default=64, help=\"number of batch_size\")\nparser.add_argument(\"-e\", \"--epochs\", type=int, default=10, help=\"number of epochs\")\nparser.add_argument(\"-w\", \"--num_workers\", type=int, default=5, help=\"dataloader worker size\")\nparser.add_argument(\"-steps\", \"--warm_up_step\", type=int, default=1000, help=\"dataloader worker size\")\n\nparser.add_argument(\"--with_cuda\", type=bool, default=True, help=\"training with CUDA: true, or false\")\nparser.add_argument(\"--log_freq\", type=int, default=10, help=\"printing loss every n iter: setting n\")\nparser.add_argument(\"--corpus_lines\", type=int, default=None, help=\"total number of lines in corpus\")\nparser.add_argument(\"--cuda_devices\", type=int, nargs='+', default=None, help=\"CUDA device ids\")\nparser.add_argument(\"--on_memory\", type=bool, default=True, help=\"Loading on memory: true or false\")\n\nparser.add_argument(\"--lr\", type=float, default=1e-3, help=\"learning rate of adam\")\nparser.add_argument(\"--adam_weight_decay\", type=float, default=0.01, help=\"weight_decay of adam\")\nparser.add_argument(\"--adam_beta1\", type=float, default=0.9, help=\"adam first beta value\")\nparser.add_argument(\"--adam_beta2\", type=float, default=0.999, help=\"adam first beta value\")\nargs = parser.parse_args(\"\")","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.721108Z","iopub.execute_input":"2022-04-08T08:26:06.721873Z","iopub.status.idle":"2022-04-08T08:26:06.737503Z","shell.execute_reply.started":"2022-04-08T08:26:06.721832Z","shell.execute_reply":"2022-04-08T08:26:06.736803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"betas=(0.9, 0.999)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.739222Z","iopub.execute_input":"2022-04-08T08:26:06.740306Z","iopub.status.idle":"2022-04-08T08:26:06.747161Z","shell.execute_reply.started":"2022-04-08T08:26:06.740271Z","shell.execute_reply":"2022-04-08T08:26:06.74625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.748642Z","iopub.execute_input":"2022-04-08T08:26:06.749181Z","iopub.status.idle":"2022-04-08T08:26:06.757459Z","shell.execute_reply.started":"2022-04-08T08:26:06.749139Z","shell.execute_reply":"2022-04-08T08:26:06.756722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ScheduledOptim():\n    '''A simple wrapper class for learning rate scheduling'''\n\n    def __init__(self, optimizer, d_model, n_warmup_steps):\n        self._optimizer = optimizer\n        self.n_warmup_steps = n_warmup_steps\n        self.n_current_steps = 0\n        self.init_lr = np.power(d_model, -0.5)\n\n    def step_and_update_lr(self):\n        \"Step with the inner optimizer\"\n        self._update_learning_rate()\n        self._optimizer.step()\n\n    def zero_grad(self):\n        \"Zero out the gradients by the inner optimizer\"\n        self._optimizer.zero_grad()\n\n    def _get_lr_scale(self):\n        return np.min([\n            np.power(self.n_current_steps, -0.5),\n            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps])\n\n    def _update_learning_rate(self):\n        ''' Learning rate scheduling per step '''\n\n        self.n_current_steps += 1\n        lr = self.init_lr * self._get_lr_scale()\n\n        for param_group in self._optimizer.param_groups:\n            param_group['lr'] = lr","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.760392Z","iopub.execute_input":"2022-04-08T08:26:06.761068Z","iopub.status.idle":"2022-04-08T08:26:06.770394Z","shell.execute_reply.started":"2022-04-08T08:26:06.761038Z","shell.execute_reply":"2022-04-08T08:26:06.769515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim import Adam\noptim = Adam(model.parameters(), lr=args.lr, betas=betas, weight_decay=args.adam_weight_decay)\noptim_schedule = ScheduledOptim(optim, args.hidden, n_warmup_steps=args.warm_up_step)\n#criterion = nn.NLLLoss(ignore_index=0)\n#log_freq = args.log_freq","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.771539Z","iopub.execute_input":"2022-04-08T08:26:06.77231Z","iopub.status.idle":"2022-04-08T08:26:06.781228Z","shell.execute_reply.started":"2022-04-08T08:26:06.772269Z","shell.execute_reply":"2022-04-08T08:26:06.780356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.parameters()\ncriterion = nn.NLLLoss(ignore_index=0)\nbinayLoss = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.782711Z","iopub.execute_input":"2022-04-08T08:26:06.783212Z","iopub.status.idle":"2022-04-08T08:26:06.789834Z","shell.execute_reply.started":"2022-04-08T08:26:06.783177Z","shell.execute_reply":"2022-04-08T08:26:06.78898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_loss = 0.0\ntotal_correct = 0\ntotal_element = 0","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.791307Z","iopub.execute_input":"2022-04-08T08:26:06.791935Z","iopub.status.idle":"2022-04-08T08:26:06.79808Z","shell.execute_reply.started":"2022-04-08T08:26:06.791881Z","shell.execute_reply":"2022-04-08T08:26:06.797383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"121\n106\n16\n83\n144\n110\n95\n10\n44\n33\n19\n23\n150\n50\n104\n53\n39","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.798996Z","iopub.execute_input":"2022-04-08T08:26:06.800537Z","iopub.status.idle":"2022-04-08T08:26:06.809067Z","shell.execute_reply.started":"2022-04-08T08:26:06.800496Z","shell.execute_reply":"2022-04-08T08:26:06.808286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampleData, b = train_data[39]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.810454Z","iopub.execute_input":"2022-04-08T08:26:06.810833Z","iopub.status.idle":"2022-04-08T08:26:06.833069Z","shell.execute_reply.started":"2022-04-08T08:26:06.810797Z","shell.execute_reply":"2022-04-08T08:26:06.832217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampleData[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.834194Z","iopub.execute_input":"2022-04-08T08:26:06.834654Z","iopub.status.idle":"2022-04-08T08:26:06.840454Z","shell.execute_reply.started":"2022-04-08T08:26:06.834617Z","shell.execute_reply":"2022-04-08T08:26:06.839672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#b[0].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.841898Z","iopub.execute_input":"2022-04-08T08:26:06.842679Z","iopub.status.idle":"2022-04-08T08:26:06.855811Z","shell.execute_reply.started":"2022-04-08T08:26:06.842624Z","shell.execute_reply":"2022-04-08T08:26:06.854693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(train_data)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.860309Z","iopub.execute_input":"2022-04-08T08:26:06.861274Z","iopub.status.idle":"2022-04-08T08:26:06.865741Z","shell.execute_reply.started":"2022-04-08T08:26:06.861236Z","shell.execute_reply":"2022-04-08T08:26:06.864982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docIdxs = [i+1 for i in range(len(train_data))] #starts from index 1","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.867122Z","iopub.execute_input":"2022-04-08T08:26:06.86784Z","iopub.status.idle":"2022-04-08T08:26:06.874263Z","shell.execute_reply.started":"2022-04-08T08:26:06.867805Z","shell.execute_reply":"2022-04-08T08:26:06.873437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(docIdxs)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.87704Z","iopub.execute_input":"2022-04-08T08:26:06.878026Z","iopub.status.idle":"2022-04-08T08:26:06.885174Z","shell.execute_reply.started":"2022-04-08T08:26:06.877997Z","shell.execute_reply":"2022-04-08T08:26:06.884362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#b,c = train_data[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.886358Z","iopub.execute_input":"2022-04-08T08:26:06.887161Z","iopub.status.idle":"2022-04-08T08:26:06.892767Z","shell.execute_reply.started":"2022-04-08T08:26:06.887117Z","shell.execute_reply":"2022-04-08T08:26:06.892036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#c.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.894071Z","iopub.execute_input":"2022-04-08T08:26:06.894842Z","iopub.status.idle":"2022-04-08T08:26:06.900826Z","shell.execute_reply.started":"2022-04-08T08:26:06.894759Z","shell.execute_reply":"2022-04-08T08:26:06.90006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(c.repeat(1,5)).reshape(-1).shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.902365Z","iopub.execute_input":"2022-04-08T08:26:06.903274Z","iopub.status.idle":"2022-04-08T08:26:06.90899Z","shell.execute_reply.started":"2022-04-08T08:26:06.903074Z","shell.execute_reply":"2022-04-08T08:26:06.908295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#d, e = model.forward(b[0].to(device), b[2].to(device))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.910372Z","iopub.execute_input":"2022-04-08T08:26:06.91083Z","iopub.status.idle":"2022-04-08T08:26:06.916952Z","shell.execute_reply.started":"2022-04-08T08:26:06.910792Z","shell.execute_reply":"2022-04-08T08:26:06.916207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#d.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.918401Z","iopub.execute_input":"2022-04-08T08:26:06.918846Z","iopub.status.idle":"2022-04-08T08:26:06.924914Z","shell.execute_reply.started":"2022-04-08T08:26:06.918809Z","shell.execute_reply":"2022-04-08T08:26:06.924258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#e.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.927152Z","iopub.execute_input":"2022-04-08T08:26:06.928465Z","iopub.status.idle":"2022-04-08T08:26:06.933948Z","shell.execute_reply.started":"2022-04-08T08:26:06.928433Z","shell.execute_reply":"2022-04-08T08:26:06.933161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_out(predList):\n    return (torch.vstack(code_pred).reshape(-1))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.936284Z","iopub.execute_input":"2022-04-08T08:26:06.937196Z","iopub.status.idle":"2022-04-08T08:26:06.941986Z","shell.execute_reply.started":"2022-04-08T08:26:06.93716Z","shell.execute_reply":"2022-04-08T08:26:06.94124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_trueLabel(labelTensors_,batchSize):\n    return (labelTensors_.repeat(1,batchSize)).reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.943224Z","iopub.execute_input":"2022-04-08T08:26:06.943574Z","iopub.status.idle":"2022-04-08T08:26:06.95058Z","shell.execute_reply.started":"2022-04-08T08:26:06.943539Z","shell.execute_reply":"2022-04-08T08:26:06.949843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calBinaryLoss(batchSize, codePred,label_tensors):\n    pred_tens = process_out(codePred)\n    true_tens = process_trueLabel(label_tensors, batchSize)\n    return binayLoss(pred_tens, true_tens.to(device))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.952532Z","iopub.execute_input":"2022-04-08T08:26:06.953037Z","iopub.status.idle":"2022-04-08T08:26:06.960818Z","shell.execute_reply.started":"2022-04-08T08:26:06.952986Z","shell.execute_reply":"2022-04-08T08:26:06.960066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.962572Z","iopub.execute_input":"2022-04-08T08:26:06.963119Z","iopub.status.idle":"2022-04-08T08:26:06.969982Z","shell.execute_reply.started":"2022-04-08T08:26:06.963079Z","shell.execute_reply":"2022-04-08T08:26:06.969211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nfor epoch in range(epochs):\n    print('Training for epoch ',epoch+1)\n    random.shuffle(docIdxs)\n    codeTensor = train_data.topCode()\n    start = time.time()\n    for docIdx in docIdxs:\n        print(docIdx)\n        trainTensors, labelTensors = train_data[docIdx]\n        batch_Size = trainTensors[0].shape[0]\n        \n        mask_lm_output, code_mask_lm_out, bert_text, bert_codeText, code_pred = model(trainTensors[0].to(device), trainTensors[2].to(device), codeTensor[0].to(device), codeTensor[2].to(device))\n        #next_loss = criterion(next_sent_output, trainTensors[3].to(device))\n        \n        print(\"\\t\",batch_Size )\n        #print(bert_text.shape,bert_codeText.shape, mask_lm_output.shape, code_mask_lm_out.shape)\n        mask_loss_text = criterion(mask_lm_output.transpose(1, 2), trainTensors[1].to(device))\n        mask_loss_code = criterion(code_mask_lm_out.transpose(1, 2), codeTensor[1].to(device))\n        loss = mask_loss_text + mask_loss_code + calBinaryLoss(batch_Size, code_pred,labelTensors ) #+ next_loss\n        if True:\n                optim_schedule.zero_grad()\n                loss.backward()\n                optim_schedule.step_and_update_lr()\n        # next sentence prediction accuracy\n        #correct = next_sent_output.argmax(dim=-1).eq(trainTensors[3].to(device)).sum().item()\n        avg_loss += loss.item()\n        #total_correct += correct\n        total_element += trainTensors[3].nelement()\n    #print(\"avg_acc\",(total_correct / (total_element ))* 100)\n    print(\"avg_loss\", avg_loss / (epoch + 1))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:06.972771Z","iopub.execute_input":"2022-04-08T08:26:06.973128Z","iopub.status.idle":"2022-04-08T08:26:08.558123Z","shell.execute_reply.started":"2022-04-08T08:26:06.973092Z","shell.execute_reply":"2022-04-08T08:26:08.557176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print((time.time()-start)/60)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.559218Z","iopub.status.idle":"2022-04-08T08:26:08.560129Z","shell.execute_reply.started":"2022-04-08T08:26:08.559876Z","shell.execute_reply":"2022-04-08T08:26:08.559903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#codeTensor[1].shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.561232Z","iopub.status.idle":"2022-04-08T08:26:08.562128Z","shell.execute_reply.started":"2022-04-08T08:26:08.561875Z","shell.execute_reply":"2022-04-08T08:26:08.561901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(code_pred[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.56321Z","iopub.status.idle":"2022-04-08T08:26:08.564018Z","shell.execute_reply.started":"2022-04-08T08:26:08.563776Z","shell.execute_reply":"2022-04-08T08:26:08.563801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.tensor(code_pred)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.566347Z","iopub.status.idle":"2022-04-08T08:26:08.566957Z","shell.execute_reply.started":"2022-04-08T08:26:08.56673Z","shell.execute_reply":"2022-04-08T08:26:08.566753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#code_pred[0].shape, code_pred[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.568094Z","iopub.status.idle":"2022-04-08T08:26:08.56873Z","shell.execute_reply.started":"2022-04-08T08:26:08.568483Z","shell.execute_reply":"2022-04-08T08:26:08.568507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.cat((code_pred[0].reshape(1,-1),code_pred[1].reshape(1,-1)), axis = 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.569886Z","iopub.status.idle":"2022-04-08T08:26:08.570502Z","shell.execute_reply.started":"2022-04-08T08:26:08.570259Z","shell.execute_reply":"2022-04-08T08:26:08.570284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#code_pred[0],code_pred[1]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.571656Z","iopub.status.idle":"2022-04-08T08:26:08.572251Z","shell.execute_reply.started":"2022-04-08T08:26:08.572026Z","shell.execute_reply":"2022-04-08T08:26:08.572049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#torch.vstack(code_pred).reshape(-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.573395Z","iopub.status.idle":"2022-04-08T08:26:08.574004Z","shell.execute_reply.started":"2022-04-08T08:26:08.573778Z","shell.execute_reply":"2022-04-08T08:26:08.573801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calBinaryLoss(5,code_pred,labelTensors)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.575134Z","iopub.status.idle":"2022-04-08T08:26:08.575758Z","shell.execute_reply.started":"2022-04-08T08:26:08.575522Z","shell.execute_reply":"2022-04-08T08:26:08.575546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#labelTensors.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.576915Z","iopub.status.idle":"2022-04-08T08:26:08.577536Z","shell.execute_reply.started":"2022-04-08T08:26:08.577295Z","shell.execute_reply":"2022-04-08T08:26:08.577319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'bertML.model')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.57867Z","iopub.status.idle":"2022-04-08T08:26:08.579269Z","shell.execute_reply.started":"2022-04-08T08:26:08.57904Z","shell.execute_reply":"2022-04-08T08:26:08.579064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T08:26:08.580418Z","iopub.status.idle":"2022-04-08T08:26:08.581027Z","shell.execute_reply.started":"2022-04-08T08:26:08.580798Z","shell.execute_reply":"2022-04-08T08:26:08.580822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}